---
title: "blog_content_draft"
format: html
---

```{r}
#| label: setup
#| include: false

# =================================================================
# Setup: Global Options and Libraries
# =================================================================

# Set code chunk defaults for cleaner output
knitr::opts_chunk$set(
  tidy = FALSE,                # Preserve code formatting
  size = "small",              # Use slightly smaller font for code
  message = FALSE,             # Suppress messages in output
  options(scipen = 1,          # Prefer standard numeric formatting (no scientific notation)
          knitr.kable.NA = '') # Display empty cells instead of "NA" in tables
)

# Load required libraries
library(tidyverse)    # Core packages: dplyr, ggplot2, readr, tibble, etc.
library(purrr)        # Functional programming tools (mapping, iteration)
library(readr)        # Fast and friendly reading of rectangular data
library(stringr)      # String manipulation utilities
library(tibble)       # Modern, clean data frames
library(kableExtra)   # Table formatting for nicer presentation
library(tidytext)     # Text mining and natural language processing
library(colorspace)   # Color palettes and manipulation
library(wordcloud2)   # Clearly for wordclouds
library(gganimate)    # Animation stuff yay

# Load cleaned datasets
nyt <- read_csv("../data/wrangled/nyt_news_data_wrangled.csv")
fox <- read_csv("../data/wrangled/fox_news_data_wrangled.csv")
## guttmacher <- read_csv("../data/Guttmatcher_institute_data/your_guttmacher_file.csv")  
```

```{r}
#| label: top-words-check

# Tokenize text into individual words
tokens <- bind_rows(
  nyt |> mutate(outlet = "NYT"),
  fox |> mutate(outlet = "Fox")
) |>
  unnest_tokens(word, text) |>
  anti_join(stop_words)  # Remove standard English stop words first

# Additional stop words
custom_stopwords <- tibble(word = c(
  "said", "ms", "mr", "mrs",
  "fox", "news", "nyt", "new", "york", "times",
  "u.s", "one", "two", "also", "would", "including", "don’t", "that’s", "it’s", "wrote", "told",
  "roe"
))
```

```{r}
#| label: clean-tokens

# Tokenize and remove both standard and custom stop words
tokens2 <- bind_rows(
  nyt |> mutate(outlet = "NYT"),
  fox |> mutate(outlet = "Fox")
) |>
  unnest_tokens(word, text) |>
  anti_join(stop_words) |>         # Remove standard English stop words
  anti_join(custom_stopwords)       # Remove custom filler/irrelevant words
```

Long a topic of debate across law, medicine, gender, and religion, abortion has remained one of the most polarizing issues in American public life. That polarization deepened in June 2022, when the Supreme Court’s decision in Dobbs v. Jackson Women’s Health Organization overturned Roe v. Wade, the 1973 ruling that had established a constitutional right to abortion.The decision unsettled not only the legal framework around abortion, but also the way the issue is discussed across the country. As states move in sharply different directions, media coverage has had to grapple with new divisions, new language, and new stakes. 

At its core, the public debate still turns on a simple but deeply charged question: is abortion good or bad? How that question gets answered–or even framed–depends heavily on where one looks. News coverage of abortion varies sharply by ideological leaning. Conservative media outlets often emphasize religious and legal arguments by focusing on fetal personhood, state-level bans, and moral appeals (Williams, 2024). In contrast, liberal media frequently frame abortion in terms of bodily autonomy, healthcare access, and gender justice, while emphasizing the disproportionate impact of abortion restrictions on marginalized communities (Human Rights Watch, 2023). These competing narratives do more than reflect existing viewpoints but actively shape public perception of abortion legislation.

In this blog, we examine how abortion is framed by two ideologically distinct media outlets: Fox News and The New York Times. To trace how these narratives evolved, we analyzed abortion-related news coverage from both sources before and after the Dobbs decision. These platforms were chosen not only for their national prominence and broad audiences, but also for their well-documented political leanings–Fox News is widely recognized as a conservative outlet, while The New York Times is identified as liberal-leaning (Pew Research Center, 2014; Mitchell et al., 2020). By comparing these two sources, we aim to better understand how media framing reflects and reinforces broader ideological divides around abortion. Using text and sentiment analysis, topic modeling, and geographic data from the Guttmacher Institute, we explore how media narratives align with state-level abortion laws and how discourse evolves in response to shifting legal landscapes.

## How Often Was Abortion Covered? Volume of Coverage Over Time

We collected a total of `3,168` abortion-related news articles. `1,739` were from Fox News and the remaining `1,429` were from The New York Times between 2020 and 2024. The chart below traces the cumulative number of articles over time to show how coverage evolved across both outlets.

```{r}
#| label: plot-timeline
#| echo: false

# Ensure pub_date is in Date format
nyt <- nyt |> mutate(pub_date = as.Date(pub_date))
fox <- fox |> mutate(pub_date = as.Date(pub_date))

# Combine datasets with outlet labels
nyt_time <- nyt |> mutate(outlet = "NYT")
fox_time <- fox |> mutate(outlet = "Fox")
all_time <- bind_rows(nyt_time, fox_time)

# Plotting the timeline

all_time |>
  filter(!is.na(pub_date)) |> 
  count(pub_date, outlet) |>
  group_by(outlet) |>
  arrange(pub_date) |>
  mutate(cumulative_articles = cumsum(n)) |> 
  ggplot(aes(x = pub_date, y = cumulative_articles, fill = outlet)) +
  geom_area(alpha = 0.8, color = "white", size = 0.2) +  # Stacked areas
  geom_vline(xintercept = as.Date("2022-06-24"), 
             linetype = "dashed", color = "gray50", size = 0.8) +
  annotate("text", x = as.Date("2022-06-24") + 30, y = Inf, 
           label = "Dobbs Decision\n(June 24, 2022)", 
           vjust = 1.5, hjust = 0, size = 3.5, color = "gray50", fontface = "italic") +
  scale_fill_manual(values = c("NYT" = "#263995", "Fox" = "#d81f25")) +
  scale_x_date(date_breaks = "6 months", date_labels = "%b %Y") +
  scale_y_continuous(labels = scales::comma) +
  labs(
    title = "Cumulative Coverage of Abortion-Related Articles (Stacked Area Chart)",
    subtitle = "Tracking cumulative reporting over time | Dobbs Decision and 2024 Election marked",
    x = NULL,
    y = "Cumulative Number of Articles",
    fill = NULL
  ) 

```

## Top Words

```{r}
#| label: plot-top-words

# Recount top words separately for NYT
top_words_nyt <- tokens2 |>
  filter(outlet == "NYT") |>
  count(word, sort = TRUE) |>
  slice_max(n, n = 20)

# Recount top words separately for Fox
top_words_fox <- tokens2 |>
  filter(outlet == "Fox") |>
  count(word, sort = TRUE) |>
  slice_max(n, n = 20)

# Plot NYT Top 20
top_words_nyt |>
  ggplot(aes(x = reorder(word, n), y = n)) +
  geom_col(fill = "#263995") +
  coord_flip() +
  labs(
    title = "Top 20 Most Frequent Words from the New York Times",
    x = "Word",
    y = "Count"
  ) 

# Plot Fox Top 20
top_words_fox |>
  ggplot(aes(x = reorder(word, n), y = n)) +
  geom_col(fill = "#d81f25") +
  coord_flip() +
  labs(
    title = "Top 20 Most Frequent Words from Fox News",
    x = "Word",
    y = "Count"
  ) 
```

## Top Bigrams

```{r}
#| label: plot-top-bigrams-by-outlet

# Tokenize bigrams separately
bigrams <- bind_rows(
  nyt |> mutate(outlet = "NYT"),
  fox |> mutate(outlet = "Fox")
) |>
  unnest_tokens(bigram, text, token = "ngrams", n = 2) |>
  separate(bigram, into = c("word1", "word2"), sep = " ") |>
  filter(
    !word1 %in% stop_words$word,
    !word2 %in% stop_words$word,
    !word1 %in% custom_stopwords$word,
    !word2 %in% custom_stopwords$word
  ) |>
  mutate(bigram = paste(word1, word2)) |>
  select(outlet, bigram)

# Recount top bigrams separately for NYT
top_bigrams_nyt <- bigrams |>
  filter(outlet == "NYT") |>
  count(bigram, sort = TRUE) |>
  slice_max(n, n = 20)

# Recount top bigrams separately for Fox
top_bigrams_fox <- bigrams |>
  filter(outlet == "Fox") |>
  count(bigram, sort = TRUE) |>
  slice_max(n, n = 20)

# Plot NYT Top 20 Bigrams
top_bigrams_nyt |>
  ggplot(aes(x = reorder(bigram, n), y = n)) +
  geom_col(fill = "#263995") +
  coord_flip() +
  labs(
    title = "Top 20 Most Frequent Bigrams from the New York Times",
    x = "Bigram",
    y = "Count"
  )

# Plot Fox Top 20 Bigrams
top_bigrams_fox |>
  ggplot(aes(x = reorder(bigram, n), y = n)) +
  geom_col(fill = "#d81f25") +
  coord_flip() +
  labs(
    title = "Top 20 Most Frequent Bigrams from Fox News",
    x = "Bigram",
    y = "Count"
  )

```

```         
```

## Word Cloud

```{r}
#| label: nyt-unigrams-wordcloud2

library(wordcloud2)
# NYT Unigrams Word Cloud
wordcloud2(top_words_nyt, 
           color = "#263995", 
           backgroundColor = "white", 
           size = 0.8)

wordcloud2(top_words_fox, 
           color = "#d81f25", 
           backgroundColor = "white", 
           size = 0.8)
```

## 

```{r}
#| label: cumulative-animate-fixed

library(gganimate)
library(tidyverse)
library(gganimate)

# Rebuild cumulative data, filling in dates
cumulative_data <- all_time |>
  filter(!is.na(pub_date)) |> 
  count(pub_date, outlet) |>
  complete(pub_date = seq.Date(min(pub_date), max(pub_date), by = "day"), outlet, fill = list(n = 0)) |> 
  group_by(outlet) |>
  arrange(pub_date) |>
  mutate(cumulative_articles = cumsum(n)) |> 
  ungroup()

# Now plot
cumulative_plot <- cumulative_data |>
  ggplot(aes(x = pub_date, y = cumulative_articles, fill = outlet, group = outlet)) +
  geom_area(stat = "identity", alpha = 0.8, color = "white", size = 0.2) +
  geom_vline(xintercept = as.Date("2022-06-24"), linetype = "dashed", color = "black", size = 0.8) +
  geom_vline(xintercept = as.Date("2024-11-05"), linetype = "dashed", color = "gray50", size = 0.8) +
  scale_fill_manual(values = c("NYT" = "#263995", "Fox" = "#d81f25")) +
  labs(
    title = "Cumulative Coverage of Abortion-Related Articles",
    subtitle = "Animated Over Time | Dobbs Decision and 2024 Election Marked",
    x = NULL,
    y = "Cumulative Number of Articles",
    fill = NULL
  ) +
  transition_reveal(pub_date)

# Animate
animation <- animate(
  cumulative_plot,
  fps = 20, duration = 10,
  width = 800, height = 500,
  renderer = gifski_renderer()
)

# View
animation

# Save
anim_save("cumulative_articles.gif", animation = animation)
```

## Sentiment Before and After

```{r}
# 1. Recode roe_status cleanly first
all_time <- all_time |>
  mutate(
    roe_status = case_when(
      roe_status %in% c("Pre-R", "Pre-Roe", "Pre-Roe Decision") ~ "Before Dobbs",
      roe_status %in% c("Post-Roe", "Post-Roe Decision") ~ "After Dobbs",
      TRUE ~ roe_status
    )
  )

# 2. Now tokenize AFTER cleaning
tokens <- all_time |>
  unnest_tokens(word, text_clean) |>
  anti_join(stop_words, by = "word")

# 3. Count words by (fixed) roe_status
top_words_period <- tokens |>
  count(roe_status, word, sort = TRUE) |>
  group_by(roe_status) |>
  slice_max(n, n = 20) |> 
  ungroup()

# 4. Plot clean Top Words
library(ggplot2)

top_words_period |>
  ggplot(aes(x = reorder_within(word, n, roe_status), y = n, fill = roe_status)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~roe_status, scales = "free_y") +
  scale_x_reordered() +
  coord_flip() +
  scale_fill_manual(values = c("Before Dobbs" = "#263995", "After Dobbs" = "#d81f25")) +
  labs(
    title = "Top Words Before and After the Dobbs Decision",
    x = "Word",
    y = "Count"
  ) +
  theme_minimal(base_size = 14)

```

```{r}

```
