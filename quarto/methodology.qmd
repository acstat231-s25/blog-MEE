---
title: "Methodology"
---

## Data Collection

This project examines abortion-related media coverage from **Fox News** and **The New York Times** between **January 1, 2020** and **December 31, 2024**. This period captures narratives both before and after the Supreme Court’s *Dobbs v. Jackson Women’s Health Organization* decision.

We employed distinct scraping strategies for each outlet due to differences in their online archive structures.  
- For **The New York Times**, we retrieved articles by crawling search results generated from [the Times' internal search portal](https://www.nytimes.com/search?query=abortion&startDate=2020-01-01&endDate=2024-12-31) using the query term "abortion."
- For **Fox News**, we extracted articles directly from [the abortion topic page](https://www.foxnews.com/category/politics/judiciary/abortion) under the Politics section.

We also collected **state-level abortion policy data** from the [Guttmacher Institute](https://www.guttmacher.org/). This supplementary dataset provides context for the evolving legal environment surrounding abortion access.

We conducted scraping and extraction with **Python 3.11**. The final corpus consists of **[will update]** articles from *Fox News*, **[will update]** articles from *The New York Times*, and a set of Guttmacher policy documents.

## Tools and Workflow

Although R was emphasized throughout the course for data analysis, we used **Python** for the web scraping stage. Python offered stronger support for interacting with dynamic websites, handling JavaScript-rendered content, managing browsing sessions, and automating browser behavior. These tasks would have been more limited or unstable if performed in R.

We used the following open-source Python libraries:

- `selenium`:  
  This library automates web browsers. It mimics human behavior such as scrolling, clicking, and loading dynamic content.

- `beautifulsoup4`:  
  This library parses HTML documents and extracts specific elements such as article text, publication dates, and authorship information.

- `requests`:  
  This library sends direct HTTP requests to retrieve static web pages without needing a full browser.

- `stem` (Tor network):  
  This library controls Tor circuits and connections. It routes scraping traffic through anonymous Tor relays to minimize the risk of IP blocking and to enhance anonymity during data collection.

- `curl_cffi`:  
  This library provides a Python interface to `libcurl`, a low-level tool for making fast, secure HTTP requests. It allows more reliable downloading of web content, especially from websites that block basic requests or require advanced TLS handling.

After collecting the data, we structured metadata fields (title, date, author, URL) and article full texts into standardized datasets for further analysis. 

## Analytical Strategy

We designed our analytical approach to integrate major techniques covered in class, including **spatial analysis**, **text analysis**, and **unsupervised learning**.

- **Spatial Analysis**:  
  We created a map of reproductive health laws across the United States. We geocoded policy data from the Guttmacher Institute and mapped it to highlight regional variation in abortion restrictions and protection. 

- **Text Analysis**:  
  We conducted sentiment analysis with `AFINN` to measure emotional tone in articles from *Fox News* and *The New York Times*. We also extracted the most frequent bigrams and keywords to compare dominant narrative structures before and after the *Dobbs* decision.

- **Unsupervised Learning**:  
  We applied Latent Dirichlet Allocation (LDA) topic modeling with `gensim`. We trained separate models for the pre-*Dobbs* and post-*Dobbs* periods to see shifts in dominant topics and thematic emphases across media outlets.
