---
title: "analyze_fox_news"
format: html
---



## 5. Text Analysis
Here we investigate the Fox News Articles from 

```{r}
#| label: bigrams

fox_meta3 |>
  unnest_tokens(bigram, text_clean, token = "ngrams", n = 2) |>
  separate(bigram, c("word1", "word2"), sep = " ") |>
  filter(!word1 %in% stop_words$word, !word2 %in% stop_words$word) |>
  unite(bigram, word1, word2, sep = " ") |>
  count(bigram, sort = TRUE) |>
  slice_max(n, n = 15) |>
  ggplot(aes(n, reorder(bigram, n))) +
  geom_col(fill = "darkorange") +
  labs(title = "Top Bigrams", x = "Count", y = "")
```

```{r}
#| label: afinn
afinn <- get_sentiments("afinn")

#This analysis looks through the text for more specific tags such as religious, medical, gender, and legal tags 
top_junk <- c("news", "said", "people", "mr", "fox", "u.s", "including", "justice", "a", "the", "abortion", "supreme", "court", "it's")
health <- c("health", "clinic", "medicine", "pills", "planned parenthood")
gender <- c("female", "females", "women", "woman", "girl", "girls")
legal <- c("illegal", "legal", "court", "ruling", "law")

fox_text_content <- fox_meta3 |> 
  unnest_tokens(sentence, text, token = "sentences")|> 
  mutate(terms = if_else(str_detect(sentence, str_c(health, collapse = "|")), 
                           "Health", NA)) |>
  mutate(terms = if_else(
    str_detect(sentence, str_c(gender, collapse = "|")), if_else(is.na(terms), "Gender", 
                                   paste(terms, "Gender", sep = ", ")), terms))|> 
  mutate(terms = if_else(
    str_detect(sentence, str_c(legal, collapse = "|")), if_else(is.na(terms), "Legal", 
                                   paste(terms, "Legal", sep = ", ")), terms))
  
fox_text_content <- fox_text_content|> 
  filter(!is.na(terms))

fox_text_content |> 
  group_by(terms) |> 
  summarise(occurance = n()) |>
  kable()

write.csv(fox_text_content, "/Users/emilieward/Documents/GitHub/blog-MEE.fox_text_content.csv")

```

In this next part of the key word analysis we will take a look the words in the sentences with these tags to understand what are the general topics and points of conversation around these keywords. 

```{r}
word_freq <- fox_text_content |>
  unnest_tokens(word, sentence) |> 
  anti_join(stop_words) 

set.seed(53)

png("/Users/emilieward/Desktop/gendercloud.png", width = 500, height = 500)
word_freq_gender <- word_freq |> 
  filter(str_detect(terms, "Gender")) |> 
  filter(!str_detect(word, str_c(top_junk, collapse =  "|"))) |> 
  filter(!str_detect(word, str_c(gender, collapse =  "|")))|> 
  count(word, sort = TRUE) |> 
  with(wordcloud(words = word, freq = n, max.words = 50))
dev.off()

png("/Users/emilieward/Desktop/healthcloud.png", width = 500, height = 500)
word_freq_health <- word_freq |> 
  filter(str_detect(terms, "Health")) |> 
  filter(!str_detect(word, str_c(top_junk, collapse =  "|")))|> 
  filter(!str_detect(word, str_c(health, collapse =  "|")))|> 
  count(word, sort = TRUE) |> 
  with(wordcloud(words = word, freq = n, max.words = 50))
dev.off()

png("/Users/emilieward/Desktop/legalcloud.png", width = 500, height = 500)
word_freq_law <- word_freq |> 
  filter(str_detect(terms, "Legal")) |> 
  filter(!str_detect(word, str_c(top_junk, collapse =  "|")))|> 
  filter(!str_detect(word, str_c(legal, collapse =  "|")))|> 
  count(word, sort = TRUE) |> 
  with(wordcloud(words = word, freq = n, max.words = 50))
dev.off()

```

## 6. Bigrams

In this sections we begin to explore the different relationship and trends through figures. We isolate and consolidate different factors to see different trends, from the mention of keywords to the date that it was published

```{r}
#| label: custom-stopwords
fox_meta3 |>
  unnest_tokens(word, text_clean) |>
  count(word, sort = TRUE) |>
  filter(!word %in% stop_words$word) |>
  slice_max(n, n = 50)  # look at common terms that weren't removed

# Top frequent words not already removed
top_junk <- c("news", "said", "people", "mr", "fox", "u.s", "including", "justice", "a", "the", "abortion", "supreme", "court")

# Bind to standard stop word list
custom_stop <- tibble(word = top_junk)
all_stops <- bind_rows(stop_words, custom_stop)

fox_meta_topwords <- fox_meta3 |>
  select(text, title) |> 
  unnest_tokens(word, text, token = "ngrams", n= 1) |> 
  filter(!word %in% top_junk) |> 
  filter(!word %in% all_stops$word) |> 
  filter(!str_detect(word, "\\d+")) |>
  group_by(title) |> 
  summarize(text_cleaned = paste(word, collapse = " "),.groups = "drop") 
fox_meta4 <- left_join(fox_meta3, fox_meta_topwords)

g_topbigram <- fox_meta_topwords |>
  unnest_tokens(bigram, text_cleaned, token = "ngrams", n = 2) |>
  count(bigram, sort = TRUE) |>
  slice_max(n, n = 15) |>
  ggplot(aes(n, reorder(bigram, n))) +
  geom_col(fill = "darkorange") +
  labs(title = "Top Bigrams", x = "Count", y = "")
g_topbigram

```





## Animating the Bigram plot 
Here we used the bigrams from the cleaned text in our previous analysis to analyze the changes in the top words used in fox articles throughou the month in 2020 to 2024. 
```{r}
# =================================================================
# Creating the animated bigram figure
# =================================================================

# attach date and tokenize from our previously filtered data set
bigram_formatted <- fox_meta4 |>
  unnest_tokens(bigram, text_cleaned, token = "ngrams", n = 2) |>
  mutate(month = floor_date(pub_date, "month")) |>
  count(month, bigram, sort = TRUE) |>
  group_by(month) |>
  slice_max(n, n = 10, with_ties = FALSE) |>  # Top 10 bigrams per month
  mutate(rank = rank(-n, ties.method = "first"),
         Value_lbl = as.character(n)) |>
  ungroup()


#This created the static plot with all the different bigrams 
staticplot <- ggplot(bigram_formatted,
                     aes(rank, group = bigram,
                         fill = as.factor(bigram), color = as.factor(bigram))) +
  geom_tile(aes(y = n / 2, height = n, width = 0.9), alpha = 0.8, color = NA) +
  geom_text(aes(y = 0, label = paste(bigram, " ")), hjust = 1, color = "black") +
  geom_text(aes(y = n, label = Value_lbl), hjust = 0, color = "black") +
  coord_flip(clip = "off", expand = FALSE) +
  scale_x_reverse() +
  guides(color = FALSE, fill = FALSE) +
  theme_minimal(base_size = 15) +
  theme(
    axis.text = element_blank(),
    axis.title = element_blank(),
    panel.grid = element_blank(),
    plot.title = element_text(size = 24, face = "bold", hjust = 0.5, color = "gray20"),
    plot.subtitle = element_text(size = 18, face = "italic", hjust = 0.5, color = "gray40"),
    plot.caption = element_text(size = 10, face = "italic", hjust = 0.5, color = "gray40"),
    plot.margin = margin(2, 2, 2, 4, "cm")
  ) +
  labs(title = "Top Bigrams in Fox Articles",
       subtitle = 'Month: {closest_state}',
       caption = "Data from Fox Roe Coverage",
       x = "", y = "")

#Created this so I can seperate the different months of the static plot and animate it
animated_barchart <- staticplot +
  transition_states(month, transition_length = 4, state_length = 1) +
  ease_aes('cubic-in-out')

animate(animated_barchart, fps = 10, duration = 40, width = 800, height = 600)

```
